{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "\n",
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install h5py\n",
    "!pip install sys\n",
    "!pip install os\n",
    "!pip install time\n",
    "!pip install glob\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install Ipython\n",
    "!pip install warnings\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mixalis/Seagate Expansion Drive/TU Delft/DeepLearning/Project/.env/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import several packages that will be used throughout\n",
    "\n",
    "# numeric packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# filesystem and OS\n",
    "import sys, os, time\n",
    "import glob\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# these magics ensure that external modules that are modified are also automatically reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "#from imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from tensorflow.contrib.metrics import streaming_mean_iou\n",
    "from keras.objectives import *\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../classifier/keras-utils/\")\n",
    "sys.path.append(\"../classifier/keras-models/\")\n",
    "\n",
    "# from multi_gpu import make_parallel\n",
    "import keras_utils as ku\n",
    "# from vgg16 import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workdir = \"/home/adalbert/nbserver/tf-workspace/deepsat-experiments/\"\n",
    "# os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and set up batching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "train_dir = \"../deepsat-data/img/train/\"\n",
    "test_dir = \"../deepsat-data/img/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324000 images belonging to 6 classes.\n",
      "Found 81000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generator for preprocessing images for data augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def apply_mean(image_data_generator):\n",
    "    \"\"\"Subtracts the VGG dataset mean\"\"\"\n",
    "    image_data_generator.mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3, 1, 1))\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=[1,1.2],\n",
    "        vertical_flip=True,\n",
    "        rotation_range=15,\n",
    "        horizontal_flip=True)\n",
    "apply_mean(train_datagen)\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "apply_mean(test_datagen)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \\\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         target_size=(224,224),\n",
    "                                         shuffle=True)\n",
    "    \n",
    "# this is a similar generator, for validation data\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \\\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         target_size=(224,224),\n",
    "                                         shuffle=True)\n",
    "\n",
    "# get class labels\n",
    "class2ind = train_generator.class_indices\n",
    "ind2class = {v:k for k,v in class2ind.items()}\n",
    "\n",
    "N_CLASSES = len(ind2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50, 224, 224, 3), (50, 6), 0.0, 0.98304904)\n"
     ]
    }
   ],
   "source": [
    "for Xbatch, ybatch in train_generator:\n",
    "    print(Xbatch.shape, ybatch.shape, Xbatch.min(), Xbatch.max())\n",
    "    break\n",
    "    \n",
    "x_train = np.zeros(shape=(len(train_generator)/200,672,672,3),dtype=np.float32)\n",
    "y_train = np.zeros(shape=(len(train_generator)/200,672,672,1),dtype=np.float32)\n",
    "\n",
    "\n",
    "x_test = np.zeros(shape=(len(test_generator)/200,672,672,3),dtype=np.float32)\n",
    "y_test = np.zeros(shape=(len(test_generator)/200,672,672,1),dtype=np.float32)\n",
    "\n",
    "for i in range(len(train_generator)/200):\n",
    "    temp = train_generator.next()\n",
    "    for k in range(672): \n",
    "        for l in range(3):\n",
    "            x_train[i][k][l*224:(l+1)*224] = temp[0][(k/224)*3+l][k%224]\n",
    "            y_train[i][k][l*224:(l+1)*224] = np.argmax(temp[1][(k/224)*3+l])\n",
    "  \n",
    "for i in range(len(test_generator)/200):\n",
    "    temp = test_generator.next()\n",
    "    for k in range(672): \n",
    "        for l in range(3):\n",
    "            x_test[i][k][l*224:(l+1)*224] = temp[0][(k/224)*3+l][k%224]\n",
    "            y_test[i][k][l*224:(l+1)*224] = np.argmax(temp[1][(k/224)*3+l])\n",
    "\n",
    "\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "test_datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define architectures to use\n",
    "Load weights from model pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG-16, pre-trained on ImageNet\n",
    "Note that the weights are trained on BGR data for this architecture (probably following Caffe's convention). It turns out that they're a good enough starting point even if using RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build the convolutional base of the VGG16 network\n",
    "model = vgg16(n_classes=N_CLASSES, input_shape=(224,224,3), fcn=False)\n",
    "\n",
    "weights_file = \"../vgg16_weights.h5\"\n",
    "model = ku.load_weights_into_model(model, weights_file, transpose_conv=True, \n",
    "                        layers_to_skip=[\"dense8\"])\n",
    "\n",
    "freeze_layers = [] #['conv1', 'conv2']\n",
    "for l in model.layers:\n",
    "    l.trainable = len([x for x in freeze_layers if x in l.name])==0 and \\\n",
    "                    len(l.get_weights())>0\n",
    "\n",
    "for l in model.layers:\n",
    "    print l.name, [x.sum() for x in l.get_weights()], l.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet initialized with ImageNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../deep-learning-models/\")\n",
    "sys.path.append(\"../classifier/\")\n",
    "\n",
    "from keras.layers import Flatten, Dense, Convolution2D\n",
    "from keras.models import Model\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from FCNresnet50 import ResNet50\n",
    "from FCNresnet50 import BilinearUpSampling2D\n",
    "from keras.preprocessing import image\n",
    "from imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "# Softmax cross-entropy loss function for pascal voc segmentation\n",
    "# and models which do not perform softmax.\n",
    "# tensorlow only\n",
    "def softmax_sparse_crossentropy_ignoring_last_label(y_true, y_pred):\n",
    "    y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "    log_softmax = tf.nn.log_softmax(y_pred)\n",
    "\n",
    "    y_true = K.one_hot(tf.to_int32(K.flatten(y_true)), K.int_shape(y_pred)[-1]+1)\n",
    "    unpacked = tf.unstack(y_true, axis=-1)\n",
    "    y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "\n",
    "    cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "    cross_entropy_mean = K.mean(cross_entropy)\n",
    "\n",
    "    return cross_entropy_mean\n",
    "\n",
    "\n",
    "\n",
    "def sparse_accuracy_ignoring_last_label(y_true, y_pred):\n",
    "    nb_classes = K.int_shape(y_pred)[-1]\n",
    "    y_pred = K.reshape(y_pred, (-1, nb_classes))\n",
    "    y_true = K.one_hot(tf.to_int32(K.flatten(y_true)),\n",
    "                       nb_classes + 1)\n",
    "    unpacked = tf.unstack(y_true, axis=-1)\n",
    "    legal_labels = ~tf.cast(unpacked[-1], tf.bool)\n",
    "    y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "\n",
    "    return K.sum(tf.to_float(legal_labels & K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))) / K.sum(tf.to_float(legal_labels))\n",
    "\n",
    "\n",
    "\n",
    "model = ResNet50(weights=None, include_top=True,input_shape=(672,672,3),classes=6)\n",
    "\n",
    "#model.layers.pop() # Get rid of the classification layer\n",
    "# model.layers.pop()\n",
    "# model.layers.pop()\n",
    "#model.outputs = [model.layers[-1].output]\n",
    "#model.output_layers = [model.layers[-1]] # added this line in addition to zo7 solution\n",
    "#model.layers[-1].outbound_nodes = []\n",
    "\n",
    "# fcn = Convolution2D(N_CLASSES, (1, 1), kernel_initializer='he_normal', activation='linear', \n",
    "#                       padding='valid', strides=(3, 3))(model.layers[-1].output)\n",
    "# fcn = BilinearUpSampling2D(size=(32, 32))(fcn)\n",
    "# model = Model(input=model.input, output=fcn)\n",
    "\n",
    "#newClassificationLayer = Dense(N_CLASSES, activation='softmax')(model.layers[-1].output)\n",
    "#model = Model(input=model.input, output=newClassificationLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load previously-saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model from checkpoint\n",
    "# model_file = \"vgg16-deepsat-best-checkpoint.h5\"\n",
    "\n",
    "# # with tf.device('/cpu:0'):\n",
    "# # load model and weights\n",
    "# model = keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spread model computation on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_parallel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-62cf367eeacd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# this uses the TensorFlow backend to spread computation on multiple GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPUS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'make_parallel' is not defined"
     ]
    }
   ],
   "source": [
    "GPUS = [0,1,2,3]\n",
    "\n",
    "# this uses the TensorFlow backend to spread computation on multiple GPUs\n",
    "model_gpu = make_parallel(model, GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Define model behavior with callbacks and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# callback for a custom learning rate decay schedule\n",
    "\n",
    "LR_DECAY_PER_EPOCH = 2.0 #1.1\n",
    "BASE_LR = 1\n",
    "\n",
    "lr_scheduler = lambda epoch: BASE_LR * LR_DECAY_PER_EPOCH**(-(epoch/10))\n",
    "lr_decay_callback = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# callback to checkpoint best model\n",
    "model_checkpoint_callback = ModelCheckpoint(\"resnet-deepsat-imagenet-best-checkpoint.h5\", monitor='val_acc', \\\n",
    "                                      verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# compile model\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "model.compile(loss=softmax_sparse_crossentropy_ignoring_last_label, \\\n",
    "            metrics=[sparse_accuracy_ignoring_last_label],\\\n",
    "            optimizer=Adadelta(lr=BASE_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/1000 [..............................] - ETA: 5:33:27 - loss: 6.1793 - sparse_accuracy_ignoring_last_label: 0.1280"
     ]
    }
   ],
   "source": [
    "# Logs to TensorBoard, new one for each run\n",
    "\n",
    "log_path_tensorboard = \"./logs/\"\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# now = time.strftime(\"%c\")\n",
    "now = str(int(time.time()))\n",
    "tensorboard_callback_fn = TensorBoard(log_dir=log_path_tensorboard + now, \\\n",
    "                                histogram_freq=1, \\\n",
    "                                write_graph=True, \\\n",
    "                                write_images=False)\n",
    "\n",
    "# Train model\n",
    "\n",
    "history = model.fit_generator(\n",
    "                train_datagen.flow(x_train, y_train, batch_size=2),\n",
    "                samples_per_epoch=2000,\n",
    "                nb_epoch=50,\n",
    "                validation_data=test_datagen.flow(x_test, y_test,batch_size=2),\n",
    "                callbacks = [lr_decay_callback, \\\n",
    "                            model_checkpoint_callback],\n",
    "                nb_val_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "ax[0].plot(history.history['loss'], label=\"train\")\n",
    "ax[0].plot(history.history['val_loss'], label=\"test\")\n",
    "ax[0].set_title(\"Loss\", fontsize=14)\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].legend(loc=\"best\")\n",
    "ax[1].plot(history.history['acc'], label=\"train\")\n",
    "ax[1].plot(history.history['val_acc'], label=\"test\")\n",
    "ax[1].set_title(\"Accuracy\", fontsize=14)\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
